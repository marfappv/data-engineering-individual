{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing NFT Price Class Prediction System with SageMaker Built-In Algorithm\n",
    "_**Making Price Class Suggestion for NFT Using Factorization Machines**_\n",
    "\n",
    "--- \n",
    "\n",
    "*This work is based on content from [Implementing Recommender System notebook](https://github.com/aws-samples/sagemaker-ml-workflow-with-apache-airflow/blob/master/notebooks/amazon-video-recommender_using_fm_algo.ipynb)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "  1. [Explore](#Explore)\n",
    "  1. [Clean](#Clean)\n",
    "  1. [Prepare](#Prepare)\n",
    "1. [Model Training](#Model-Training)\n",
    "1. [Model Inference](#Model-Inference)\n",
    "  1. [Real-Time Inference](#Real-Time-Inference)\n",
    "  1. [Batch Inference](#Batch-Inference)\n",
    "1. [Evaluate Model Performance](#Evaluate-Model-Performance)\n",
    "1. [Model Tuning](#Model-Tuning)\n",
    "1. [Wrap-up](#Wrap-up)\n",
    "  1. [Clean-Up](#Clean-up-(optional))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "In many ways, recommender systems were a catalyst for the current popularity of machine learning.  One of Amazon's earliest successes was the \"Customers who bought this, also bought...\" feature, while the million dollar Netflix Prize spurred research, raised public awareness, and inspired numerous other data science competitions.\n",
    "\n",
    "Recommender systems can utilize a multitude of data sources and ML algorithms, and most combine various unsupervised, supervised, and reinforcement learning techniques into a holistic framework.  However, the core component is almost always a model which predicts a user's rating (or purchase) for a certain item based on that user's historical ratings of similar items as well as the behavior of other similar users.  The minimal required dataset for this is a history of user item ratings.  In our case, we'll use 1 to 5 star ratings from over 2M Amazon customers on over 160K digital videos. More details on this dataset can be found at its [AWS Public Datasets page](https://s3.amazonaws.com/amazon-reviews-pds/readme.html).\n",
    "\n",
    "Matrix factorization has been the cornerstone of most user-item prediction models.  This method starts with the large, sparse, user-item ratings in a single matrix, where users index the rows, and items index the columns.  It then seeks to find two lower-dimensional, dense matrices which, when multiplied together, preserve the information and relationships in the larger matrix.\n",
    "\n",
    "![image](./factorization.png)\n",
    "\n",
    "Matrix factorization has been extended and generalized with deep learning and embeddings.  These techniques allows us to introduce non-linearities for enhanced performance and flexibility.  This notebook will fit a neural network-based model to generate recommendations for the Amazon video dataset.  It will start by exploring our data in the notebook, training a model on the data and fit our model using a SageMaker managed training cluster.  We'll then deploy to an endpoint and check our method.\n",
    "\n",
    "We will also see how the tasks in the machine learning pipeline can be orchestrated and automated through Apache Airflow integration with Sagemaker.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.t2.xlarge notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `get_execution_role()` call with the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TypeError: 'NoneType' object is not subscriptable\n",
    "\n",
    "bucket = 's3a://airflow-sagemaker-cd6fd720'\n",
    "prefix = 'sagemaker/fm-recsys'\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics, TrainingJobAnalytics\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "smclient = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the Python libraries we'll need for the remainder of this example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/nbformat/current.py:15: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  warnings.warn(\"\"\"nbformat.current is deprecated.\n"
     ]
    }
   ],
   "source": [
    "#Essentials\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from pandas.api.types import CategoricalDtype\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np; np.random.seed(2022)\n",
    "import random\n",
    "\n",
    "#Image creation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import pyplot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#Image display\n",
    "from IPython.display import Image as image\n",
    "from IPython.display import display\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#Metrics of accuracy\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "#Other\n",
    "import psycopg2 as pg\n",
    "from nbformat import current\n",
    "import itertools as it\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from scipy.sparse import lil_matrix\n",
    "import boto3\n",
    "import json\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker.predictor import json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot aesthetics\n",
    "sns.set(color_codes=True)\n",
    "sns.set_context('paper')\n",
    "five_thirty_eight = [\"#30a2da\", \"#fc4f30\", \"#e5ae38\", \"#6d904f\", \"#8b8b8b\",]\n",
    "sns.set_palette(five_thirty_eight)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "### Explore\n",
    "\n",
    "Let's start by bringing in our dataset from an S3 public bucket.  As mentioned above, this contains 1 to 5 star ratings from over 2M Amazon customers on over 160K digital videos.  More details on this dataset can be found at its [AWS Public Datasets page](https://s3.amazonaws.com/amazon-reviews-pds/readme.html).\n",
    "\n",
    "_Note, because this dataset is over a half gigabyte, the load from S3 may take ~10 minutes.  Also, since Amazon SageMaker Notebooks start with a 5GB persistent volume by default, and we don't need to keep this data on our instance for long, we'll bring it to the temporary volume (which has up to 20GB of storage)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir /tmp/recsys/\n",
    "#!aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz /tmp/recsys/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the data into a Pandas DataFrame so that we can begin to understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_name</th>\n",
       "      <th>created_date</th>\n",
       "      <th>collection_status</th>\n",
       "      <th>nft_version</th>\n",
       "      <th>tokens</th>\n",
       "      <th>owner_number</th>\n",
       "      <th>featured</th>\n",
       "      <th>hidden</th>\n",
       "      <th>nsfw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dispatch-Messaging</td>\n",
       "      <td>2022-04-06T21:49:20.343522</td>\n",
       "      <td>not_requested</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7356207.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>2022-04-12T17:54:03.412074</td>\n",
       "      <td>not_requested</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3050053.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ASTER EGGZ</td>\n",
       "      <td>2022-04-12T17:49:14.605766</td>\n",
       "      <td>not_requested</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>7471608.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Testv2chib2</td>\n",
       "      <td>2022-04-12T17:51:35.428359</td>\n",
       "      <td>not_requested</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5909669.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test Model 4</td>\n",
       "      <td>2022-04-12T17:50:33.114878</td>\n",
       "      <td>not_requested</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>7396100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      collection_name                created_date collection_status  \\\n",
       "0  Dispatch-Messaging  2022-04-06T21:49:20.343522     not_requested   \n",
       "1                test  2022-04-12T17:54:03.412074     not_requested   \n",
       "2         3ASTER EGGZ  2022-04-12T17:49:14.605766     not_requested   \n",
       "3         Testv2chib2  2022-04-12T17:51:35.428359     not_requested   \n",
       "4        Test Model 4  2022-04-12T17:50:33.114878     not_requested   \n",
       "\n",
       "  nft_version tokens  owner_number  featured  hidden   nsfw  \n",
       "0        None   None     7356207.0     False   False  False  \n",
       "1         3.0      1     3050053.0     False   False  False  \n",
       "2        None      0     7471608.0     False   False  False  \n",
       "3        None      0     5909669.0     False   False  False  \n",
       "4         3.0   None     7396100.0     False   False  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = pg.connect(\"dbname='opensea' user='marfapopova21' host='opensea.c5pkb2dzarva.us-west-2.rds.amazonaws.com' port='5432' password='qwerty123'\")\n",
    "df1 = pd.read_sql('select * from nfts.collections', con=engine)\n",
    "df1 = df1.dropna(how='all', axis=1)\n",
    "df1 = df1.dropna(how='all')\n",
    "df1.head()\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_name</th>\n",
       "      <th>asset_contract_type</th>\n",
       "      <th>require_email</th>\n",
       "      <th>day_avg_price</th>\n",
       "      <th>week_avg_price</th>\n",
       "      <th>month_avg_price</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>total_supply</th>\n",
       "      <th>max_price</th>\n",
       "      <th>min_price</th>\n",
       "      <th>average_price</th>\n",
       "      <th>only_proxied_transfers</th>\n",
       "      <th>is_subject_to_whitelist</th>\n",
       "      <th>opensea_buyer_fee_basis_points</th>\n",
       "      <th>opensea_seller_fee_basis_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dispatch-Messaging</td>\n",
       "      <td>semi-fungible</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>non-fungible</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ASTER EGGZ</td>\n",
       "      <td>non-fungible</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Testv2chib2</td>\n",
       "      <td>non-fungible</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test Model 4</td>\n",
       "      <td>non-fungible</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      collection_name asset_contract_type  require_email  day_avg_price  \\\n",
       "0  Dispatch-Messaging       semi-fungible          False            0.0   \n",
       "1                test        non-fungible          False            0.0   \n",
       "2         3ASTER EGGZ        non-fungible          False            0.0   \n",
       "3         Testv2chib2        non-fungible          False            0.0   \n",
       "4        Test Model 4        non-fungible          False            0.0   \n",
       "\n",
       "   week_avg_price  month_avg_price  total_volume  total_sales  total_supply  \\\n",
       "0             0.0              0.0           0.0          0.0           1.0   \n",
       "1             0.0              0.0           0.0          0.0           1.0   \n",
       "2             0.0              0.0           0.0          0.0           2.0   \n",
       "3             0.0              0.0           0.0          0.0          50.0   \n",
       "4             0.0              0.0           0.0          0.0           1.0   \n",
       "\n",
       "   max_price  min_price  average_price  only_proxied_transfers  \\\n",
       "0        0.0        0.0            0.0                   False   \n",
       "1        0.0        0.0            0.0                   False   \n",
       "2        0.0        0.0            0.0                   False   \n",
       "3        0.0        0.0            0.0                   False   \n",
       "4        0.0        0.0            0.0                   False   \n",
       "\n",
       "   is_subject_to_whitelist opensea_buyer_fee_basis_points  \\\n",
       "0                    False                              0   \n",
       "1                    False                              0   \n",
       "2                    False                              0   \n",
       "3                    False                              0   \n",
       "4                    False                              0   \n",
       "\n",
       "  opensea_seller_fee_basis_points  \n",
       "0                             250  \n",
       "1                             250  \n",
       "2                             250  \n",
       "3                             250  \n",
       "4                             250  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = pg.connect(\"dbname='opensea' user='marfapopova21' host='opensea.c5pkb2dzarva.us-west-2.rds.amazonaws.com' port='5432' password='qwerty123'\")\n",
    "df2 = pd.read_sql('select * from nfts.finances', con=engine)\n",
    "df2 = df2.dropna(how='all', axis=1)\n",
    "df2 = df2.dropna(how='all')\n",
    "df2.head()\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_name</th>\n",
       "      <th>created_date</th>\n",
       "      <th>collection_status</th>\n",
       "      <th>nft_version</th>\n",
       "      <th>tokens</th>\n",
       "      <th>owner_number</th>\n",
       "      <th>featured</th>\n",
       "      <th>hidden</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>asset_contract_type</th>\n",
       "      <th>require_email</th>\n",
       "      <th>day_avg_price</th>\n",
       "      <th>week_avg_price</th>\n",
       "      <th>month_avg_price</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>total_supply</th>\n",
       "      <th>max_price</th>\n",
       "      <th>min_price</th>\n",
       "      <th>average_price</th>\n",
       "      <th>only_proxied_transfers</th>\n",
       "      <th>is_subject_to_whitelist</th>\n",
       "      <th>opensea_buyer_fee_basis_points</th>\n",
       "      <th>opensea_seller_fee_basis_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dispatch-Messaging</td>\n",
       "      <td>2022-04-06T21:49:20.343522</td>\n",
       "      <td>not_requested</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7356207.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>semi-fungible</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dispatch-Messaging</td>\n",
       "      <td>2022-04-06T21:49:20.343522</td>\n",
       "      <td>not_requested</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7356207.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>semi-fungible</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dispatch-Messaging</td>\n",
       "      <td>2022-04-11T12:25:09.603872</td>\n",
       "      <td>not_requested</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7461686.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>semi-fungible</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dispatch-Messaging</td>\n",
       "      <td>2022-04-11T12:25:09.603872</td>\n",
       "      <td>not_requested</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7461686.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>semi-fungible</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>2022-04-12T17:54:03.412074</td>\n",
       "      <td>not_requested</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3050053.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>non-fungible</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      collection_name                created_date collection_status  \\\n",
       "0  Dispatch-Messaging  2022-04-06T21:49:20.343522     not_requested   \n",
       "1  Dispatch-Messaging  2022-04-06T21:49:20.343522     not_requested   \n",
       "2  Dispatch-Messaging  2022-04-11T12:25:09.603872     not_requested   \n",
       "3  Dispatch-Messaging  2022-04-11T12:25:09.603872     not_requested   \n",
       "4                test  2022-04-12T17:54:03.412074     not_requested   \n",
       "\n",
       "  nft_version tokens  owner_number  featured  hidden   nsfw  \\\n",
       "0        None   None     7356207.0     False   False  False   \n",
       "1        None   None     7356207.0     False   False  False   \n",
       "2        None   None     7461686.0     False   False  False   \n",
       "3        None   None     7461686.0     False   False  False   \n",
       "4         3.0      1     3050053.0     False   False  False   \n",
       "\n",
       "  asset_contract_type  require_email  day_avg_price  week_avg_price  \\\n",
       "0       semi-fungible          False            0.0             0.0   \n",
       "1       semi-fungible          False            0.0             0.0   \n",
       "2       semi-fungible          False            0.0             0.0   \n",
       "3       semi-fungible          False            0.0             0.0   \n",
       "4        non-fungible          False            0.0             0.0   \n",
       "\n",
       "   month_avg_price  total_volume  total_sales  total_supply  max_price  \\\n",
       "0              0.0           0.0          0.0           1.0        0.0   \n",
       "1              0.0           0.0          0.0          34.0        0.0   \n",
       "2              0.0           0.0          0.0           1.0        0.0   \n",
       "3              0.0           0.0          0.0          34.0        0.0   \n",
       "4              0.0           0.0          0.0           1.0        0.0   \n",
       "\n",
       "   min_price  average_price  only_proxied_transfers  is_subject_to_whitelist  \\\n",
       "0        0.0            0.0                   False                    False   \n",
       "1        0.0            0.0                   False                    False   \n",
       "2        0.0            0.0                   False                    False   \n",
       "3        0.0            0.0                   False                    False   \n",
       "4        0.0            0.0                   False                    False   \n",
       "\n",
       "  opensea_buyer_fee_basis_points opensea_seller_fee_basis_points  \n",
       "0                              0                             250  \n",
       "1                              0                             250  \n",
       "2                              0                             250  \n",
       "3                              0                             250  \n",
       "4                              0                             250  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "596130"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the 2 dataframes on collection name\n",
    "df = pd.merge(df1, df2, on = 'collection_name')\n",
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['collection_name', 'created_date', 'collection_status', 'nft_version',\n",
       "       'tokens', 'owner_number', 'featured', 'hidden', 'nsfw',\n",
       "       'asset_contract_type', 'require_email', 'day_avg_price',\n",
       "       'week_avg_price', 'month_avg_price', 'total_volume', 'total_sales',\n",
       "       'total_supply', 'max_price', 'min_price', 'average_price',\n",
       "       'only_proxied_transfers', 'is_subject_to_whitelist',\n",
       "       'opensea_buyer_fee_basis_points', 'opensea_seller_fee_basis_points'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this dataset includes information like:\n",
    "\n",
    "- `collection_name`: NFT collection name.\n",
    "- `created_date`: NFT collection release date.\n",
    "- `collection_status`: \n",
    "- `nft_version`: \n",
    "- `tokens`: Total supply of NFTs in the collection (?).\n",
    "- `owner_number`: Unique owner ID number.\n",
    "- `featured`: A boolean datatype, showing whether the NFT has a featured artist (True) or is created solo (False).\n",
    "- `hidden`: \n",
    "- `nsfw`: A boolean datatype, showing whether the NFT has explicit content (True) or not (False).\n",
    "- `asset_contract_type`: \n",
    "- `require_email`: \n",
    "- `day_avg_price`: Average NFT price over 24 hours.\n",
    "- `week_avg_price`: Average NFT price over 24 hours.\n",
    "- `month_avg_price`: Average NFT price over 24 hours.\n",
    "- `total_volume`: \n",
    "- `total_sales`: \n",
    "- `total_supply`: \n",
    "- `max_price`: \n",
    "- `min_price`: \n",
    "- `average_price`: \n",
    "- `only_proxied_transfers`: \n",
    "- `is_subject_to_whitelist`:\n",
    "- `opensea_buyer_fee_basis_points`: \n",
    "- `opensea_seller_fee_basis_points`: \n",
    "\n",
    "For this example, let's limit ourselves to all but `owner_number`, `max_price`, and `min_price`. Including additional features in our system from other tables of the schema could be beneficial, but would require substantial processing (particularly the text data) which would take us beyond the scope of this notebook.\n",
    "\n",
    "*Note: we'll keep `collection_name` on the dataset to help verify our recommendations later in the notebook, but it will not be used in algorithm training.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596130"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['owner_number', 'max_price', 'min_price'], axis=1)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 596130 entries, 0 to 596129\n",
      "Data columns (total 21 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   collection_name                  455505 non-null  object \n",
      " 1   created_date                     455505 non-null  object \n",
      " 2   collection_status                596130 non-null  object \n",
      " 3   nft_version                      84029 non-null   object \n",
      " 4   tokens                           80345 non-null   object \n",
      " 5   featured                         596130 non-null  bool   \n",
      " 6   hidden                           596130 non-null  bool   \n",
      " 7   nsfw                             596130 non-null  bool   \n",
      " 8   asset_contract_type              455505 non-null  object \n",
      " 9   require_email                    596130 non-null  bool   \n",
      " 10  day_avg_price                    596130 non-null  float64\n",
      " 11  week_avg_price                   596130 non-null  float64\n",
      " 12  month_avg_price                  596130 non-null  float64\n",
      " 13  total_volume                     596130 non-null  float64\n",
      " 14  total_sales                      596130 non-null  float64\n",
      " 15  total_supply                     596130 non-null  float64\n",
      " 16  average_price                    596130 non-null  float64\n",
      " 17  only_proxied_transfers           596130 non-null  bool   \n",
      " 18  is_subject_to_whitelist          596130 non-null  bool   \n",
      " 19  opensea_buyer_fee_basis_points   596130 non-null  object \n",
      " 20  opensea_seller_fee_basis_points  596130 non-null  object \n",
      "dtypes: bool(6), float64(7), object(8)\n",
      "memory usage: 76.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     8\n",
      "float64    7\n",
      "bool       6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show number of all existing data types in the dataframe\n",
    "print(df.dtypes.astype(str).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day_avg_price</th>\n",
       "      <td>596130.0</td>\n",
       "      <td>0.012827</td>\n",
       "      <td>0.348749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_avg_price</th>\n",
       "      <td>596130.0</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>0.366626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_avg_price</th>\n",
       "      <td>596130.0</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>0.366626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_volume</th>\n",
       "      <td>596130.0</td>\n",
       "      <td>0.027223</td>\n",
       "      <td>0.705754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sales</th>\n",
       "      <td>596130.0</td>\n",
       "      <td>0.179508</td>\n",
       "      <td>5.136095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_supply</th>\n",
       "      <td>596130.0</td>\n",
       "      <td>7.523052</td>\n",
       "      <td>117.076531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_price</th>\n",
       "      <td>596130.0</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>0.366626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count      mean         std  min  25%  50%  75%      max\n",
       "day_avg_price    596130.0  0.012827    0.348749  0.0  0.0  0.0  0.0     12.5\n",
       "week_avg_price   596130.0  0.014267    0.366626  0.0  0.0  0.0  0.0     12.5\n",
       "month_avg_price  596130.0  0.014267    0.366626  0.0  0.0  0.0  0.0     12.5\n",
       "total_volume     596130.0  0.027223    0.705754  0.0  0.0  0.0  0.0     25.0\n",
       "total_sales      596130.0  0.179508    5.136095  0.0  0.0  0.0  0.0    204.0\n",
       "total_supply     596130.0  7.523052  117.076531  0.0  1.0  1.0  2.0  10169.0\n",
       "average_price    596130.0  0.014267    0.366626  0.0  0.0  0.0  0.0     12.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics of the transposed table\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3314"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['collection_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unidentified contract    326041\n",
       "CryptoPunks               26244\n",
       "Pawn Tickets              23409\n",
       "SquareNFT                 14641\n",
       "Pawn Loans                 9025\n",
       "                          ...  \n",
       "test collection               1\n",
       "Test NFT CORE                 1\n",
       "Lord Ganesha                  1\n",
       "OneCDNFT                      1\n",
       "TheImaginaryOnesNft           1\n",
       "Name: collection_name, Length: 3314, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['collection_name'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CryptoPunks            26244\n",
       "Pawn Tickets           23409\n",
       "SquareNFT              14641\n",
       "Pawn Loans              9025\n",
       "UTPN                    7396\n",
       "                       ...  \n",
       "test collection            1\n",
       "Test NFT CORE              1\n",
       "Lord Ganesha               1\n",
       "OneCDNFT                   1\n",
       "TheImaginaryOnesNft        1\n",
       "Name: collection_name, Length: 3313, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['collection_name'].value_counts().loc[lambda x : x<326041] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270089"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference between the number of all collection records in the dataset and unnamed ones\n",
    "596130 - 326041"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collections named \"Unidentified contract\" mean that their creators did not add public variable string. Hence, there are only 3313 unique collection names in the dataset, that contain 270089 labelled records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because most people haven't seen most videos, and people rate fewer videos than we actually watch, we'd expect our data to be sparse.  Our algorithm should work well with this sparse problem in general, but we may still want to clean out some of the long tail.  Let's look at some basic percentiles to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantile</th>\n",
       "      <th>all collections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.90</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.95</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.96</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.97</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.98</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.99</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00</td>\n",
       "      <td>326041.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quantile  all collections\n",
       "7       0.25              1.0\n",
       "8       0.50              1.0\n",
       "9       0.75              1.0\n",
       "10      0.90              9.0\n",
       "11      0.95             25.0\n",
       "12      0.96             25.0\n",
       "13      0.97             36.0\n",
       "14      0.98             81.0\n",
       "15      0.99            225.0\n",
       "16      1.00         326041.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantile</th>\n",
       "      <th>named collections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.90</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.95</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.96</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.97</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.98</td>\n",
       "      <td>76.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.99</td>\n",
       "      <td>225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00</td>\n",
       "      <td>26244.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quantile  named collections\n",
       "7       0.25               1.00\n",
       "8       0.50               1.00\n",
       "9       0.75               1.00\n",
       "10      0.90               9.00\n",
       "11      0.95              25.00\n",
       "12      0.96              25.00\n",
       "13      0.97              36.00\n",
       "14      0.98              76.92\n",
       "15      0.99             225.00\n",
       "16      1.00           26244.00"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantile</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.25</td>\n",
       "      <td>376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>571.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.75</td>\n",
       "      <td>2191.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.90</td>\n",
       "      <td>6520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.95</td>\n",
       "      <td>294709.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.96</td>\n",
       "      <td>352347.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.97</td>\n",
       "      <td>409985.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.98</td>\n",
       "      <td>467623.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.99</td>\n",
       "      <td>525261.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00</td>\n",
       "      <td>582899.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quantile     sales\n",
       "7       0.25     376.0\n",
       "8       0.50     571.0\n",
       "9       0.75    2191.5\n",
       "10      0.90    6520.0\n",
       "11      0.95  294709.5\n",
       "12      0.96  352347.4\n",
       "13      0.97  409985.3\n",
       "14      0.98  467623.2\n",
       "15      0.99  525261.1\n",
       "16      1.00  582899.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_collections = df['collection_name'].value_counts()\n",
    "named_collections = df['collection_name'].value_counts().loc[lambda x : x<326041] \n",
    "sales = df['total_sales'].value_counts()\n",
    "\n",
    "quantiles = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 1]\n",
    "all_collections_q = pd.DataFrame(zip(quantiles, all_collections.quantile(quantiles)), columns=[\"quantile\", \"all collections\"])\n",
    "named_collections_q = pd.DataFrame(zip(quantiles, named_collections.quantile(quantiles)), columns=[\"quantile\", \"named collections\"])\n",
    "sales_q = pd.DataFrame(zip(quantiles, sales.quantile(quantiles)), columns=[\"quantile\", \"sales\"])\n",
    "\n",
    "all_collections_q.tail(10)\n",
    "named_collections_q.tail(10)\n",
    "sales_q.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axc_all = sns.barplot(x=\"quantile\", y=\"all collections\", data=all_collections_q, palette=five_thirty_eight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axc_named = sns.barplot(x=\"quantile\", y=\"named collections\", data=named_collections_q, palette=five_thirty_eight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axs = sns.barplot(x=\"quantile\", y=\"sales\", data=sales_q, palette=five_thirty_eight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, only about 5% of customers have rated 5 or more videos, and only 25% of videos have been rated by 9+ customers.\n",
    "\n",
    "### Clean\n",
    "\n",
    "Let's filter out this long tail and remove any duplicate reviews (same product and customer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = customers[customers >= 5]\n",
    "products = products[products >= 10]\n",
    "\n",
    "print(\"# of records before removing the long tail = {:10d}\".format(reviews.shape[0]))\n",
    "reduced_df = reviews.merge(pd.DataFrame({'customer_id': customers.index})).merge(pd.DataFrame({'product_id': products.index}))\n",
    "print(\"# of records after  removing the long tail = {:10d}\".format(reduced_df.shape[0]))\n",
    "reduced_df = reduced_df.drop_duplicates(['customer_id', 'product_id'])\n",
    "print(\"# of records after  removing duplicates    = {:10d}\".format(reduced_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll recreate our customer and product lists since there are customers with more than 5 reviews, but all of their reviews are on products with less than 5 reviews (and vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = reduced_df['customer_id'].value_counts()\n",
    "products = reduced_df['product_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll number each user and item, giving them their own sequential index.  This will allow us to hold the information in a sparse format where the sequential indices indicate the row and column in our ratings matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_index = pd.DataFrame({'customer_id': customers.index, 'customer': np.arange(customers.shape[0])})\n",
    "product_index = pd.DataFrame({'product_id': products.index, \n",
    "                              'product': np.arange(products.shape[0])})\n",
    "\n",
    "reduced_df = reduced_df.merge(customer_index).merge(product_index)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the feature dimension size whch will required for preparing the training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_customer = reduced_df['customer'].max() + 1\n",
    "nb_products = reduced_df['product'].max() + 1\n",
    "feature_dim = nb_customer + nb_products\n",
    "print(nb_customer, nb_products, feature_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim down the data set to include only customer, product, star_rating which is all we need for the training algorithm to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = reduced_df[['customer', 'product', 'star_rating']]\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare\n",
    "\n",
    "We will be using SageMaker's implementation of Factorization Machines (FM) for building a recommender system. The algorithm expects float32 tensors in protobuf whereas the data sets are pandas dataframe on disk. Most of the conversion effort is handled by the Amazon SageMaker Python SDK.\n",
    "\n",
    "The FM algorithm will utilize sparse input and since the data sets are dense matrix, it has to be converted a sparse matrix with one-hot encoded feature vectors with customers and products. Thus, each sample in the data set will be a wide boolean vector with 178729 feature space (140344 customer + 38385 products) with only two values set to 1 with respect to the customer and product.\n",
    "\n",
    "Following are the next steps\n",
    "\n",
    "1. Split the cleaned data set into train and test data sets.\n",
    "2. For each set, build a sparse matrix with one-hot encoded feature vectors (customer + products) and a label vector with star ratings.\n",
    "3. Convert both the sets to protobuf encoded files.\n",
    "4. Copy these files to an Amazon S3 bucket.\n",
    "5. Configure and run a Factorization Machines training job on Amazon SageMaker.\n",
    "6. Deploy the corresponding model to an endpoint.\n",
    "7. Run predictions on test data set and validate\n",
    "\n",
    "#### Split into Training and Test Data Sets\n",
    "\n",
    "Let's start by [splitting](https://docs.scipy.org/doc/numpy/reference/generated/numpy.split.html) in training, validation and test sets.  This will allow us to estimate the model's accuracy on videos our customers rated, but wasn't included in our training. We will use validation data set specifically for tuning model hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df, test_df = np.split(\n",
    "    product_df.sample(frac=1), \n",
    "    [int(.6*len(product_df)), int(.8*len(product_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of rows in the training data set   = {:10d}\".format(train_df.shape[0]))\n",
    "print(\"# of rows in the validation data set = {:10d}\".format(validate_df.shape[0]))\n",
    "print(\"# of rows in the test data set       = {:10d}\".format(test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the feature dimensions by adding total number of (unique) customers and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature dimension\n",
    "all_df = pd.concat([train_df, validate_df, test_df])\n",
    "nb_customer = np.unique(all_df['customer'].values).shape[0]\n",
    "nb_products = np.unique(all_df['product'].values).shape[0]\n",
    "feature_dim = nb_customer + nb_products\n",
    "print(\"# of customers = {:10d}\".format(nb_customer))\n",
    "print(\"# of products  = {:10d}\".format(nb_products))\n",
    "print(\"# of features  = {:10d}\".format(feature_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Sparse One-Hot Encoded Matrix\n",
    "\n",
    "Our training matrix is now even sparser: Of all 183,833,321,511 values (1028559 rows * 178729 columns), only 2,057,118 are non-zero (1,028,559*2). In other words, the matrix is 99.99% sparse. Storing this as a dense matrix would be a massive waste of both storage and computing power. To avoid this, use a scipy.lil_matrix sparse matrix for features and a numpy array for ratings.\n",
    "\n",
    "Let's define a function that takes the data set and returns a sparse feature matrix and numpy array with ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_matrix(df, nb_rows, nb_customer, nb_products):\n",
    "    # dataframe to array\n",
    "    df_val = df.values\n",
    "\n",
    "    # determine feature size\n",
    "    nb_cols = nb_customer + nb_products\n",
    "    print(\"# of rows = {}\".format(str(nb_rows)))\n",
    "    print(\"# of cols = {}\".format(str(nb_cols)))\n",
    "\n",
    "    # extract customers and ratings\n",
    "    df_X = df_val[:, 0:2]\n",
    "    # Features are one-hot encoded in a sparse matrix\n",
    "    X = lil_matrix((nb_rows, nb_cols)).astype('float32')\n",
    "    df_X[:, 1] = nb_customer + df_X[:, 1]\n",
    "    coords = df_X[:, 0:2]\n",
    "    X[np.arange(nb_rows), coords[:, 0]] = 1\n",
    "    X[np.arange(nb_rows), coords[:, 1]] = 1\n",
    "\n",
    "    # create label with ratings\n",
    "    Y = df_val[:, 2].astype('float32')\n",
    "\n",
    "    # validate size and shape\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    assert X.shape == (nb_rows, nb_cols)\n",
    "    assert Y.shape == (nb_rows, )\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Convert training data set to one-hot encoded sparse matrix\")\n",
    "train_X, train_Y = convert_sparse_matrix(train_df, train_df.shape[0], nb_customer, nb_products)\n",
    "print(\"Convert validation data set to one-hot encoded sparse matrix\")\n",
    "validate_X, validate_Y = convert_sparse_matrix(validate_df, validate_df.shape[0], nb_customer, nb_products)\n",
    "print(\"Convert test data set to one-hot encoded sparse matrix\")\n",
    "test_X, test_Y = convert_sparse_matrix(test_df, test_df.shape[0], nb_customer, nb_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Protobuf format and Upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Sagemaker's utility function [`write_spmatrix_to_sparse_tensor`](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/amazon/common.py) to convert scipy sparse matrix to protobuf format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_protobuf(X, Y, bucket, key):\n",
    "    \"\"\"Converts features and predictions matrices to recordio protobuf and\n",
    "       writes to S3\n",
    "\n",
    "    Args:\n",
    "        X:\n",
    "          2D numpy matrix with features\n",
    "        Y:\n",
    "          1D numpy matrix with predictions\n",
    "        bucket:\n",
    "          s3 bucket where recordio protobuf file will be staged\n",
    "        prefix:\n",
    "          s3 url prefix to stage prepared data to use for training the model\n",
    "        key:\n",
    "          protobuf file name to be staged\n",
    "\n",
    "    Returns:\n",
    "        s3 url with key to the protobuf data\n",
    "    \"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    obj = '{}'.format(key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_path = save_as_protobuf(train_X, train_Y, bucket, 'prepare/train/train.protobuf')\n",
    "print(\"Training data set in protobuf format uploaded at {}\".format(s3_train_path))\n",
    "s3_val_path = save_as_protobuf(validate_X, validate_Y, bucket, 'prepare/validate/validate.protobuf')\n",
    "print(\"Validation data set in protobuf format uploaded at {}\".format(s3_val_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will chunk the test data to avoid the payload size issues when performing batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(x, batch_size):\n",
    "    \"\"\"split array into chunks of batch_size\n",
    "    \"\"\"\n",
    "    chunk_range = range(0, x.shape[0], batch_size)\n",
    "    chunks = [x[p: p + batch_size] for p in chunk_range]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_chunks = chunk(test_X, 10000)\n",
    "test_y_chunks = chunk(test_Y, 10000)\n",
    "N = len(test_x_chunks)\n",
    "for i in range(N):\n",
    "    test_data = save_as_protobuf(\n",
    "        test_x_chunks[i],\n",
    "        test_y_chunks[i],\n",
    "        bucket,\n",
    "        \"prepare/test/test_\" + str(i) + \".protobuf\")\n",
    "    print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Once we have the data preprocessed and available in the correct format for training, the next step is to actually train the model using the data. We'll use the Amazon SageMaker Python SDK to kick off training and monitor status until it is completed. In this example that takes between 4-7 minutes for 3-10 epochs. \n",
    "\n",
    "First, let's get the Sagemaker Factorization Machine container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'factorization-machines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next kick off the base estimator, making sure to pass in the necessary hyperparameters. Notice:\n",
    "\n",
    "- `feature_dim` is set to 178729, which is the number of customers + products in the training data set.\n",
    "- `predictor_type` is set to 'regressor' since we are trying to predict the rating\n",
    "- `mini_batch_size` is set to 200. This value can be tuned for relatively minor improvements in fit and speed, but selecting a reasonable value relative to the dataset is appropriate in most cases.\n",
    "- `num_factors` is set to 64. Factorization machines find a lower dimensional representation of the interactions for all features. Making this value smaller provides a more parsimonious model, closer to a linear model, but may sacrifice information about interactions. Making it larger provides a higher-dimensional representation of feature interactions, but adds computational complexity and can lead to overfitting. In a practical application, time should be invested to tune this parameter to the appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "output_location = 's3://{}/train/'.format(bucket)\n",
    "s3_train_path = 's3://{}/prepare/train/train.protobuf'.format(bucket)\n",
    "s3_val_path = 's3://{}/prepare/validate/validate.protobuf'.format(bucket)\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(container,\n",
    "                                   role, \n",
    "                                   train_instance_count=1, \n",
    "                                   train_instance_type='ml.c5.4xlarge',\n",
    "                                   output_path=output_location,\n",
    "                                   sagemaker_session=sess)\n",
    "\n",
    "fm.set_hyperparameters(feature_dim=feature_dim,\n",
    "                      predictor_type='regressor',\n",
    "                      mini_batch_size=200,\n",
    "                      num_factors=512,\n",
    "                      bias_lr=0.02,\n",
    "                      epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.fit({'train': s3_train_path,'test': s3_val_path}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker built-in algorithms automatically compute and emit a variety of model training, evaluation, and validation metrics that can be captured from Cloudwatch using Sagemaker SDK. Since we are using FM built-in algorithm with predictor type as `regressor`, we can capture RMSE (root-mean-square error) of the model that measures the differences between the predicted values and the actual values.\n",
    "\n",
    "Let's capture the RMSE of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = fm._current_job_name\n",
    "metric_name = 'train:rmse:epoch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to check current status of training job\n",
    "fm_training_job_result = smclient.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "status = fm_training_job_result['TrainingJobStatus']\n",
    "if status != 'Completed':\n",
    "    print('Reminder: the training job has not been completed.')\n",
    "else:\n",
    "    print('The training job is completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug-in the training job name and metrics to be captured\n",
    "metrics_dataframe = TrainingJobAnalytics(training_job_name=training_job_name,metric_names=[metric_name]).dataframe()\n",
    "metrics_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = metrics_dataframe.plot(kind='line', figsize=(12,5), x='timestamp', y='value', style='b.', legend=False)\n",
    "plt.set_ylabel(metric_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of epochs increased, RMSE goes down which is a good sign that the predicted values are getting closer to the actual values from the test set. We can increase number of epochs or change the hyperparameters and try to tweak the model. Let's try to deploy this model and make predictions to see how close the predictions are. Then we can run a hyper-parameter tuning job to determine the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define some common utility functions here that will be used during inference and evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_protobuf(X, Y=None):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_matrix_X(df, nb_rows, nb_customer, nb_products):\n",
    "    # dataframe to array\n",
    "    df_val = df.values\n",
    "\n",
    "    # determine feature size\n",
    "    nb_cols = nb_customer + nb_products\n",
    "    \n",
    "    # extract customers and ratings\n",
    "    df_X = df_val[:,0:2]\n",
    "    # Features are one-hot encoded in a sparse matrix\n",
    "    X = lil_matrix((nb_rows, nb_cols)).astype('float32')\n",
    "    df_X[:,1] = nb_customer + df_X[:,1]\n",
    "    coords = df_X[:,0:2]\n",
    "    X[np.arange(nb_rows), coords[:, 0]] = 1\n",
    "    X[np.arange(nb_rows), coords[:, 1]] = 1\n",
    "\n",
    "    # validate size and shape\n",
    "    assert X.shape == (nb_rows, nb_cols)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-Time Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model is trained, all it takes to deploy the model is a Sagemaker API call `deploy()` that creates the model package, sets up endpoint configuration and finally creates the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor = fm.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions could be done by sending HTTP POST requests from a separate web service, but to keep things easy, we'll just use the `.predict()` method from the SageMaker Python SDK. The API expects JSON or RecordIO format for  request and JSON for response data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor.content_type = 'application/x-recordio-protobuf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model with sample ratings from test data set using `predict()` API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pb = convert_to_protobuf(test_X[1000:1010]).getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = fm_predictor.predict(test_pb)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = [round(r['score'], 2) for r in json.loads(response)['predictions']]\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(zip(test_Y[1000:1010], predicted), columns = [\"actual_rating\", \"predicted_rating\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will perform batch inference on the test data set prepared earlier (chunking into multiple protobuf files). To run batch transform, create a model package for the transform endpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the model from the training estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_model = fm.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform batch inference on the test data set and save results to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_transformer = fm_model.transformer(\n",
    "    instance_type='ml.c4.xlarge', \n",
    "    instance_count=1, \n",
    "    strategy=\"MultiRecord\", \n",
    "    output_path=\"s3://{}/transform/\".format(bucket)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_transformer.transform(\n",
    "    data=\"s3://{}/prepare/test/\".format(bucket), \n",
    "    data_type='S3Prefix', \n",
    "    content_type=\"application/x-recordio-protobuf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Waiting for transform job: ' + fm_transformer.latest_transform_job.job_name)\n",
    "fm_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inference results will be stored in a separate file for each test file chunk. Let's download the results from S3 and merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_s3(bucket, key):\n",
    "    s3 = boto3.resource('s3')\n",
    "    obj = s3.Object( bucket, key)\n",
    "    content = obj.get()['Body'].read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "for i in range(N):\n",
    "    key = 'transform/test_' + str(i) + '.protobuf.out'\n",
    "    response = download_from_s3(bucket, key)\n",
    "    result = [json.loads(row)[\"score\"] for row in response.split(\"\\n\") if len(row) > 0]\n",
    "    test_preds.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.array(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "Let's start by calculating a naive baseline to approximate how well our model is doing.  The simplest estimate would be to assume every user item rating is just the average rating over all ratings.\n",
    "\n",
    "*Note, we could do better by using each individual video's average, however, in this case it doesn't really matter as the same conclusions would hold.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Naive MSE:', np.mean((test_df['star_rating'] - np.mean(train_df['star_rating'])) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll calculate predictions for our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE:', np.mean((test_Y - test_preds) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our neural network and embedding model produces substantially better results (~1.44 vs 1.13 on the mean square error).\n",
    "\n",
    "For recommender systems, subjective accuracy also matters.  Let's get some recommendations for a random user to see if they make intuitive sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_6 = reduced_df[reduced_df['customer'] == 6].sort_values(['star_rating', 'product'], ascending=[False, True])\n",
    "pd.concat((df_customer_6.head(10), df_customer_6.tail(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, user #6 seems to like sprawling dramamtic television series and sci-fi, but they dislike silly comedies.\n",
    "\n",
    "Now we'll loop through and predict user #6's ratings for every common video in the catalog, to see which ones we'd recommend and which ones we wouldn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_payload(cust_id, nb_customer, nb_products, product_index):\n",
    "    # prepare payload for user #6\n",
    "    c = [cust_id] * nb_products\n",
    "    p = product_index['product'].values\n",
    "    x = pd.DataFrame(zip(c,p))\n",
    "    p_x = convert_sparse_matrix_X(x, x.shape[0], nb_customer, nb_products)\n",
    "    x_pb = convert_to_protobuf(p_x)\n",
    "    return x_pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pb = create_payload(6, nb_customer, nb_products, product_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions using end-point created in Real-Time Inference\n",
    "response = fm_predictor.predict(x_pb)\n",
    "predictions = [round(r['score'], 2) for r in json.loads(response)['predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({'product': product_index['product'],\n",
    "                            'prediction': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_cust_6 = df_customer_6.merge(predictions_df, on=['product'])[['customer', 'customer_id', 'product', 'product_id', 'product_title', 'star_rating', 'prediction']]\n",
    "df_results_cust_6.sort_values(['prediction', 'product'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, our predicted highly rated shows have some well-reviewed TV dramas and some sci-fi.  Meanwhile, our bottom rated shows include goofball comedies.\n",
    "\n",
    "*Note, because of random initialization in the weights, results on subsequent runs may differ slightly.*\n",
    "\n",
    "Let's confirm that we no longer have almost perfect correlation in recommendations with user #7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pb = create_payload(7, nb_customer, nb_products, product_index)\n",
    "response = fm_predictor.predict(x_pb)\n",
    "predictions_user7 = [round(r['score'], 2) for r in json.loads(response)['predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predictions_df['prediction'], np.array(predictions_user7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "So far, we have developed a deep learning model to predict customer ratings but the model could be improved further by various techniques. In this section, let's see if tuning the hyper-parameters of Factorization Machine is going to make the model any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = 's3://{}/train/'.format(bucket)\n",
    "s3_train_path = 's3://{}/prepare/train/train.protobuf'.format(bucket)\n",
    "s3_val_path = 's3://{}/prepare/validate/validate.protobuf'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's create the estimator with Factorization Machines container similar to how we defined in training the model. Also, set the initial hyper-parameters that we know worked before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_estimator = sagemaker.estimator.Estimator(container,\n",
    "                                   role, \n",
    "                                   train_instance_count=1, \n",
    "                                   train_instance_type='ml.c5.4xlarge',\n",
    "                                   output_path=output_location,\n",
    "                                   sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_estimator.set_hyperparameters(\n",
    "    feature_dim=feature_dim,\n",
    "    predictor_type='regressor',\n",
    "    mini_batch_size=200,\n",
    "    num_factors=512,\n",
    "    bias_lr=0.02,\n",
    "    epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find best hyperparameters with Sagemaker's Automatic Model Tuning. Following hyperparameters will be tuned\n",
    "    - ***factors_lr:*** The learning rate for factorization terms.\n",
    "    - ***factors_init_sigma:*** The standard deviation for initialization of factorization terms. Takes effect if factors_init_method is set to normal.\n",
    "    \n",
    "\n",
    "- Define the hyperparameter tuning ranges to be searched and set the objective metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges=  {\n",
    "    \"factors_lr\": ContinuousParameter(0.0001, 0.2),\n",
    "    \"factors_init_sigma\": ContinuousParameter(0.0001, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we have our ranges defined we want to define our success metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"test:rmse\"\n",
    "objective_type = \"Minimize\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Start hyperparameter tuning job with the ranges defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_tuner = HyperparameterTuner(\n",
    "    estimator=fm_estimator,\n",
    "    objective_metric_name=objective_metric_name, \n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    objective_type=objective_type,\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_prefix = time.strftime(\"%Y%m%d-%H%M%S\", time.gmtime())\n",
    "fm_tuner_job_name = 'hpo-fm-' + timestamp_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_tuner.fit({'train': s3_train_path, 'test': s3_val_path}, job_name=fm_tuner_job_name, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Track hyperparameter tuning job progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to check current status of hyperparameter tuning job\n",
    "tuning_job_result = smclient.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=fm_tuner_job_name)\n",
    "\n",
    "status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "if status != 'Completed':\n",
    "    print('Reminder: the tuning job has not been completed.')\n",
    "    \n",
    "job_count = tuning_job_result['TrainingJobStatusCounters']['Completed']\n",
    "print(\"%d training jobs have completed\" % job_count)\n",
    "    \n",
    "is_minimize = (tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['Type'] != 'Maximize')\n",
    "objective_name = tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['MetricName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analyze Hyper-Parameter Tuning Job Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug-in the training job name and metrics to be captured\n",
    "fm_tuner_analytics = HyperparameterTuningJobAnalytics(hyperparameter_tuning_job_name=fm_tuner_job_name)\n",
    "df_fm_tuner_metrics = fm_tuner_analytics.dataframe()\n",
    "df_fm_tuner_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze using seaborn\n",
    "plt = df_fm_tuner_metrics.plot(kind='line', figsize=(12,5), x='TrainingStartTime', \n",
    "                             y='FinalObjectiveValue', \n",
    "                             style='b.', legend=False)\n",
    "plt.set_ylabel(objective_metric_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best Factorization Machine Model after Hyper-Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fm_tuner_job_name: \" + fm_tuner_job_name)\n",
    "fm_tuner = HyperparameterTuner.attach(fm_tuner_job_name)\n",
    "\n",
    "fm_tuner_analytics = HyperparameterTuningJobAnalytics(hyperparameter_tuning_job_name=fm_tuner_job_name)\n",
    "df_fm_tuner_metrics = fm_tuner_analytics.dataframe()\n",
    "\n",
    "fm_best_model_name = fm_tuner.best_training_job()\n",
    "print(\"fm_best_model_name: \" + fm_best_model_name)\n",
    "\n",
    "fm_model_info = smclient.describe_training_job(TrainingJobName=fm_best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fm_tuner_metrics[df_fm_tuner_metrics['TrainingJobName']==fm_best_model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's evaluate the results with the best training job from hyper-parameter tuning job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can deploy the endpoint using hyper-parameter tuning job and test the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = sagemaker.estimator.Estimator.attach(fm_best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can re-run the cells in Batch Inference and Evaluation section to evaluate the performance of the model with tuned hyper-parameters. \n",
    "\n",
    "Assuming batch inference is carried out, let's calculate predictions for our test dataset and see if we do better than the training job with default hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE:', np.mean((test_Y - test_preds) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Wrap-up\n",
    "\n",
    "In this example, we developed a deep learning model to predict customer ratings.  This could serve as the foundation of a recommender system in a variety of use cases.  However, there are many ways in which it could be improved.  For example we did very little with:\n",
    "- hyperparameter tuning\n",
    "- controlling for overfitting (early stopping, dropout, etc.)\n",
    "- testing whether binarizing our target variable would improve results\n",
    "- including other information sources (video genres, historical ratings, time of review)\n",
    "- adjusting our threshold for user and item inclusion \n",
    "\n",
    "In addition to improving the model, we could improve the engineering by:\n",
    "- Setting the context and key value store up for distributed training\n",
    "- Fine tuning our data ingestion (e.g. num_workers on our data iterators) to ensure we're fully utilizing our GPU\n",
    "- Thinking about how pre-processing would need to change as datasets scale beyond a single machine\n",
    "\n",
    "Beyond that, recommenders are a very active area of research and techniques from active learning, reinforcement learning, segmentation, ensembling, and more should be investigated to deliver well-rounded recommendations.\n",
    "\n",
    "### Clean-up (optional)\n",
    "\n",
    "Let's finish by deleting our endpoint to avoid stray hosting charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name_contains = ['-fm-', 'factorization-machines-']\n",
    "for name in endpoint_name_contains:\n",
    "    endpoints = smclient.list_endpoints(NameContains=name, StatusEquals='InService')\n",
    "    endpoint_names = [r['EndpointName'] for r in endpoints['Endpoints']]\n",
    "    for endpoint_name in endpoint_names:\n",
    "        print(\"Deleting endpoint: \" + endpoint_name)\n",
    "        smclient.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "conda_python2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
